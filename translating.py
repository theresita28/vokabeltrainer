from datetime import datetime
import csv
import re
from llama_index.core.query_engine import RetrieverQueryEngine
from llama_index.core.prompts import PromptTemplate
import pandas as pd
from llama_index.core import Document, VectorStoreIndex, Settings
from llama_index.embeddings.huggingface import HuggingFaceEmbedding
from llama_index.llms.ollama import Ollama
import pandas as pd
from datetime import date
import spacy

nlp_es = spacy.load("es_core_news_sm")
def finde_lemma(spanisches_wort: str) -> str:
    """Gibt die Grundform (Infinitiv) eines spanischen Wortes zur√ºck."""
    doc = nlp_es(spanisches_wort)
    for token in doc:
        return token.lemma_.lower()
    return spanisches_wort.lower()  # Fallback, falls kein Token erkannt wird



# === 1. MINI-INDEX vorbereiten ===
def build_test_index():
    docs = [
        Document(text="Spanisch: hola\nDeutsch: hallo", metadata={"kategorie_filter": "Grundlagen"}),
        Document(text="Spanisch: tiempo\nDeutsch: Zeit", metadata={"kategorie_filter": "Grundlagen"}),
        Document(text="Spanisch: caf√©\nDeutsch: Kaffee", metadata={"kategorie_filter": "Alltag"}),
    ]
    index = VectorStoreIndex.from_documents(docs)
    return index

# === 2. MODELLE EINSTELLEN ===
Settings.llm = Ollama(
    model="phi3:3.8b-mini-4k-instruct-q4_K_M",  # klein und sparsam
    temperature=0.1,
    base_url="http://localhost:11434"
)

Settings.embed_model = HuggingFaceEmbedding(model_name="BAAI/bge-small-en-v1.5")

def uebersetze_und_lerne(index, satz: str, csv_datei: str):
    """
    √úbersetzt einen Satz und lernt neue Vokabeln automatisch hinzu.
    """
    print(f"\n--- √úbersetze & Lerne: '{satz}' ---")

    # 1Ô∏è‚É£ Tokenisierung (vereinfachte Worterkennung)
    # Nur alphabetische Tokens (ignoriert Satzzeichen)
    tokens = re.findall(r"[A-Za-z√Å√â√ç√ì√ö√ú√ë√°√©√≠√≥√∫√º√±√Ñ√ñ√ú√ü]+", satz)
    tokens = [t.lower() for t in tokens]

    # 2Ô∏è‚É£ Pr√ºfen, ob W√∂rter im Index / CSV existieren
    vorhandene, neue = pruefe_vokabeln(csv_datei, tokens)

    # 3Ô∏è‚É£ Satz√ºbersetzung (√ºber LLM)
    uebersetzung, erklaerung = uebersetze_mit_llm(satz, neue)

    # 4Ô∏è‚É£ Neue W√∂rter automatisch zur CSV hinzuf√ºgen
    if neue:
        fuege_neue_vokabeln_hinzu(csv_datei, neue, satz)
        print("üÜï Neue W√∂rter erkannt und gespeichert:", ", ".join(neue))
    
    if vorhandene:
        print("‚úÖ Bereits bekannte W√∂rter:", ", ".join(vorhandene))

    # 5Ô∏è‚É£ Ausgabe
    print("\n--- √úbersetzung ---")
    print(uebersetzung)
    if erklaerung:
        print("\n--- Neue Vokabeln erkl√§rt ---")
        print(erklaerung)
    else:
        print("\n‚úÖ Alle W√∂rter waren bereits bekannt.")
    
    return uebersetzung


def pruefe_vokabeln(csv_datei: str, tokens: list[str]):
    """
    Pr√ºft, welche W√∂rter bereits in der CSV-Vokabelliste enthalten sind.
    Lemmatisiert spanische W√∂rter, um Grundformen zu speichern.
    Gibt zwei Mengen zur√ºck:
      - vorhandene: bekannte W√∂rter aus der CSV
      - neue: unbekannte W√∂rter, die erg√§nzt werden m√ºssen
    """
    try:
        df = pd.read_csv(csv_datei, sep=';')
    except FileNotFoundError:
        print(f"‚ö†Ô∏è  Datei '{csv_datei}' nicht gefunden ‚Äì es wird angenommen, dass keine Vokabeln existieren.")
        df = pd.DataFrame(columns=["Spanisch", "Deutsch", "Kategorie", "Beispielsatz", "last_repetition"])

    vorhandene = []
    neue = []

    for wort in tokens:
        lemma = finde_lemma(wort.lower())

        if lemma in df['Spanisch'].astype(str).str.lower().values:
            vorhandene.append(lemma)
        else:
            neue.append(lemma)

    return vorhandene, neue


def uebersetze_mit_llm(satz, neue_vokabeln):
    """
    √úbersetzt den Satz und gibt Erkl√§rungen zu unbekannten W√∂rtern.
    """
    prompt = (
        "Du bist ein Spanisch-Deutsch-√úbersetzer und Sprachlehrer.\n"
        "√úbersetze den folgenden Satz vollst√§ndig und nat√ºrlich.\n"
        "Falls einige W√∂rter nicht bekannt sind oder schwierig sein k√∂nnten, "
        "gib danach eine kurze Erkl√§rung auf Deutsch (Bedeutung und ggf. Beispiel).\n\n"
        f"Satz: {satz}\n\n"
    )
    if neue_vokabeln:
        prompt += f"Diese W√∂rter sind neu: {', '.join(neue_vokabeln)}\n"

    # Direkte LLM-Abfrage ohne Index
    try:
        response = Settings.llm.complete(prompt)
        text = response.text
    except Exception as e:
        text = f"Fehler bei der √úbersetzung: {e}"

    # Optional: Split in √úbersetzung und Erkl√§rung
    parts = text.split("\n\n", 1)
    translation = parts[0].strip()
    explanation = parts[1].strip() if len(parts) > 1 else ""

    return translation, explanation

def fuege_neue_vokabeln_hinzu(csv_datei, neue_worter, original_satz):
    """
    F√ºgt neue W√∂rter in die CSV ein mit LLM-generierten √úbersetzungen und Kategorien.
    """
    heute = datetime.now().strftime("%Y-%m-%d")
    
    # LLM-Prompt f√ºr jede neue Vokabel
    for wort in neue_worter:
        prompt = (
            f"Du bist ein Spanisch-Lehrer. Analysiere das spanische Wort '{wort}' im Kontext des Satzes:\n"
            f"'{original_satz}'\n\n"
            f"Gib folgende Informationen zur√ºck (genau in diesem Format):\n"
            f"DEUTSCH: [NUR EIN deutsches Wort als √úbersetzung, keine Erkl√§rung]\n"
            f"KATEGORIE: [passende Kategorie wie 'Alltag', 'Verben', 'Adjektive', 'Grundlagen', etc.]\n\n"
            f"Wichtig: Bei DEUTSCH nur ein einzelnes Wort angeben, keine S√§tze oder Erkl√§rungen!\n"
            f"Antworte NUR mit diesen zwei Zeilen, keine zus√§tzlichen Erkl√§rungen."
        )
        
        try:
            response = Settings.llm.complete(prompt)
            text = response.text.strip()
            
            # Parse die Antwort
            deutsch = ""
            kategorie = "Unbekannt"
            
            for line in text.split("\n"):
                if line.startswith("DEUTSCH:"):
                    deutsch = line.replace("DEUTSCH:", "").strip()
                    # Nur das erste Wort nehmen, falls mehrere zur√ºckgegeben wurden
                    deutsch = deutsch.split()[0] if deutsch else ""
                elif line.startswith("KATEGORIE:"):
                    kategorie = line.replace("KATEGORIE:", "").strip()
            
            # Fallback, falls Parsing fehlschl√§gt
            if not deutsch:
                deutsch = f"[{wort}]"
                
        except Exception as e:
            print(f"‚ö†Ô∏è  Fehler beim Abrufen der √úbersetzung f√ºr '{wort}': {e}")
            deutsch = ""
            kategorie = "Unbekannt"
        
        # Zur CSV hinzuf√ºgen - Reihenfolge muss mit CSV-Spalten √ºbereinstimmen
        neue_zeile = {
            "Spanisch": wort,
            "Deutsch": deutsch,
            "Beispielsatz": original_satz,
            "last_repetition": heute,
            "Kategorie": kategorie
            
        }
        
        # CSV erweitern
        try:
            df = pd.read_csv(csv_datei, sep=';')
            
            # Entferne leere Zeilen (alle Spalten sind leer oder NaN)
            df = df.dropna(how='all')
            
            # Pr√ºfe, welche Spalte f√ºr das Datum existiert (mit oder ohne Unterstrich)
            if 'lastrepetition' in df.columns:
                # Umbenennen: lastrepetition -> last_repetition
                df = df.rename(columns={'lastrepetition': 'last_repetition'})
            
            # Stelle sicher, dass die Spalten in der richtigen Reihenfolge sind
            spalten_reihenfolge = ["Spanisch", "Deutsch", "Beispielsatz", "last_repetition", "Kategorie"]
            
            # Pr√ºfe, ob alle ben√∂tigten Spalten vorhanden sind
            fehlende_spalten = [col for col in spalten_reihenfolge if col not in df.columns]
            if fehlende_spalten:
                print(f"‚ö†Ô∏è  Warnung: Fehlende Spalten in CSV: {fehlende_spalten}")
                # F√ºge fehlende Spalten mit leeren Werten hinzu
                for col in fehlende_spalten:
                    df[col] = ""
            
            # Falls die CSV andere Spalten hat, ordne sie neu an
            df = df[spalten_reihenfolge]
        except FileNotFoundError:
            df = pd.DataFrame(columns=["Spanisch", "Deutsch", "Beispielsatz", "last_repetition", "Kategorie"])
        
        # Neue Zeile hinzuf√ºgen mit expliziter Spaltenreihenfolge
        neue_zeile_df = pd.DataFrame([neue_zeile], columns=["Spanisch", "Deutsch", "Beispielsatz", "last_repetition", "Kategorie"])
        df = pd.concat([df, neue_zeile_df], ignore_index=True)
        
        # Nochmal leere Zeilen entfernen vor dem Speichern
        df = df.dropna(how='all')
        
        # Sicherstellen, dass beim Speichern die Spaltenreihenfolge erhalten bleibt
        df = df[["Spanisch", "Deutsch", "Beispielsatz", "last_repetition", "Kategorie"]]
        df.to_csv(csv_datei, sep=';', index=False)
        
        print(f"   ‚úì {wort} ‚Üí {deutsch} ({kategorie})")
    
    print(f"üÜï {len(neue_worter)} neue Vokabel(n) mit √úbersetzung hinzugef√ºgt.")


if __name__ == "__main__":

    index = build_test_index()
    uebersetze_und_lerne(index,satz="Ellos estudian ciencias.",csv_datei="../vokabeln.csv")